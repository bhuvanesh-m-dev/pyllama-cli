# 🦙 PyLlama-CLI

**PyLlama-CLI** is a lightweight, offline-first command-line tool built in Python that uses local Ollama LLMs like TinyLlama to generate intelligent responses without internet connectivity. It is part of the [PyLlamaUI project](https://github.com/bhuvanesh-m-dev/pyllamaui), aimed at enhancing autonomous workflows using offline and online AI with future API support.

---

## 🚀 Features

- 🧠 Fully offline AI assistant using Ollama models  
- 💻 Command-line interface (CLI) for quick prompt-and-response  
- 💾 Saves generated responses as text files  
- 🔄 Easy to expand with new models or APIs  
- 🌐 Future-ready for online API integrations and hybrid AI workflows  

---

## 🧰 Requirements

### 🔧 Software

- **Python** 3.8+
- **Ollama** – https://ollama.com (must be installed)
- **TinyLlama model** (download with Ollama):
  ```bash
  ollama pull tinyllama
